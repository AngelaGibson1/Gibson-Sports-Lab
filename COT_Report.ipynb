{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+SUVM01FFeChb4ocgKn4B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AngelaGibson1/Gibson-Sports-Lab/blob/main/COT_Report.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "4VxrkqAabbSl",
        "outputId": "3829ec4e-ceb4-4549-95e0-72cbbaa4e6b8"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'J:\\\\Strategy and Analytics Group\\\\Balances\\\\COT\\\\CFTC_-_NYMEX_-_WTI.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8a27bca63354>\u001b[0m in \u001b[0;36m<cell line: 130>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0moutput_html_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr'J:\\Strategy and Analytics Group\\Balances\\COT\\COT_Report2.html'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m \u001b[0manalyze_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_html_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-8a27bca63354>\u001b[0m in \u001b[0;36manalyze_data\u001b[0;34m(files_info, output_html_path)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile_info\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles_info\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'file_path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#Convert date - this will help with table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1448\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1706\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    861\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    864\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'J:\\\\Strategy and Analytics Group\\\\Balances\\\\COT\\\\CFTC_-_NYMEX_-_WTI.csv'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "def analyze_data(files_info, output_html_path):\n",
        "    combined_year_data = pd.DataFrame()\n",
        "    combined_table_data = pd.DataFrame()\n",
        "\n",
        "    summaries = []\n",
        "\n",
        "    for file_info in files_info:\n",
        "        data = pd.read_csv(file_info['file_path'])\n",
        "\n",
        "#Convert date - this will help with table\n",
        "        data['Date'] = pd.to_datetime(data['Date'])\n",
        "\n",
        "#Filter\n",
        "        filtered_data = data[(data[file_info['group_column']] == file_info['group_name']) & (data[file_info['type_column']] == file_info['item_type'])]\n",
        "\n",
        "#We can filter longer than a year, but it does crowd the graph! 1 year was the settled agreement\n",
        "        one_year_ago = pd.Timestamp.now() - pd.DateOffset(years=1)\n",
        "        year_data = filtered_data[filtered_data['Date'] >= one_year_ago]\n",
        "        year_data = year_data.sort_values(by='Date')\n",
        "\n",
        "#Combining year data\n",
        "        year_data['Source'] = file_info['title']\n",
        "        combined_year_data = pd.concat([combined_year_data, year_data], ignore_index=True)\n",
        "\n",
        "#For the table -- we need past two weeks data\n",
        "        latest_date = filtered_data['Date'].max()\n",
        "        two_weeks_ago = latest_date - pd.DateOffset(weeks=2)\n",
        "        two_week_data = filtered_data[filtered_data['Date'] >= two_weeks_ago].sort_values(by='Date')\n",
        "\n",
        "#Change vs the prior week\n",
        "        two_week_data['Previous_Week_Position'] = two_week_data['Position'].shift(1)\n",
        "        two_week_data['Change'] = two_week_data['Position'] - two_week_data['Previous_Week_Position']\n",
        "\n",
        "#Table --\n",
        "        two_week_data = two_week_data[['Date', 'Position', 'Previous_Week_Position', 'Change']].dropna()\n",
        "        two_week_data['Source'] = file_info['title']\n",
        "        combined_table_data = pd.concat([combined_table_data, two_week_data], ignore_index=True)\n",
        "\n",
        "#Stats\n",
        "        if not two_week_data.empty:\n",
        "            latest_position = two_week_data.iloc[-1]['Position']\n",
        "            previous_week_position = two_week_data.iloc[-2]['Position'] if len(two_week_data) > 1 else None\n",
        "            change = two_week_data.iloc[-1]['Change']\n",
        "            latest_date_str = two_week_data.iloc[-1]['Date'].strftime('%b %d, %Y')\n",
        "            summaries.append((file_info['title'], latest_date_str, latest_position, previous_week_position, change))\n",
        "\n",
        "#Dropdown options\n",
        "    dropdown_options = []\n",
        "    for title in combined_year_data['Source'].unique():\n",
        "        dropdown_options.append({'label': title, 'value': title})\n",
        "\n",
        "    fig = go.Figure()\n",
        "\n",
        "    for title in combined_year_data['Source'].unique():\n",
        "        data = combined_year_data[combined_year_data['Source'] == title]\n",
        "        fig.add_trace(go.Scatter(x=data['Date'], y=data['Position'], mode='lines', name=title, visible=True if title == dropdown_options[0]['value'] else False))\n",
        "\n",
        "#Summary\n",
        "    annotations = []\n",
        "    for summary in summaries:\n",
        "        title, latest_date_str, latest_position, previous_week_position, change = summary\n",
        "        if latest_position is not None and previous_week_position is not None and change is not None:\n",
        "            annotations.append(dict(\n",
        "                xref='paper', yref='paper',\n",
        "                x=1.05, y=1,\n",
        "                xanchor='left', yanchor='bottom',\n",
        "                text=f\"<b>{title}</b><br>Date: {latest_date_str}<br>Latest Position: {latest_position}<br>Previous Week Position: {previous_week_position}<br>Change: {change}\",\n",
        "                showarrow=False,\n",
        "                font=dict(size=10)\n",
        "            ))\n",
        "\n",
        "    fig.update_layout(\n",
        "        title='Net Position of Managed Money in Various Markets (Past Year)',\n",
        "        xaxis_title='Date',\n",
        "        yaxis_title='Net Position',\n",
        "        updatemenus=[\n",
        "            {\n",
        "                'buttons': [\n",
        "                    {\n",
        "                        'args': [{'visible': [title == option['value'] for title in combined_year_data['Source'].unique()]}],\n",
        "                        'label': option['label'],\n",
        "                        'method': 'update'\n",
        "                    } for option in dropdown_options\n",
        "                ],\n",
        "                'direction': 'down',\n",
        "                'showactive': True,\n",
        "            }\n",
        "        ],\n",
        "        annotations=annotations\n",
        "    )\n",
        "\n",
        "#Bottom table with all data, helpful for summary.\n",
        "    table_fig = go.Figure(data=[go.Table(\n",
        "        header=dict(values=['Source', 'Date', 'Position', 'Previous Week Position', 'Change'],\n",
        "                    fill_color='paleturquoise',\n",
        "                    align='left'),\n",
        "        cells=dict(values=[combined_table_data['Source'], combined_table_data['Date'].dt.strftime('%b %d, %Y'), combined_table_data['Position'], combined_table_data['Previous_Week_Position'], combined_table_data['Change']],\n",
        "                   fill_color='lavender',\n",
        "                   align='left'))\n",
        "    ])\n",
        "\n",
        "    table_fig.update_layout(title='Net Managed Money Position (Past Two Weeks)')\n",
        "\n",
        "    with open(output_html_path, 'w') as f:\n",
        "        f.write(fig.to_html(full_html=False, include_plotlyjs='cdn'))\n",
        "        f.write(table_fig.to_html(full_html=False, include_plotlyjs='cdn'))\n",
        "\n",
        "    fig.show()\n",
        "    table_fig.show()\n",
        "\n",
        "#IMPORTANT -- we can add more, but lets keep naming consistent\n",
        "files_info = [\n",
        "    {'file_path': r'J:\\Strategy and Analytics Group\\Balances\\COT\\CFTC_-_NYMEX_-_WTI.csv', 'group_name': 'Managed Money', 'item_type': 'Net', 'group_column': 'group_name', 'type_column': 'Type', 'title': 'NYMEX - WTI'},\n",
        "    {'file_path': r'J:\\Strategy and Analytics Group\\Balances\\COT\\CFTC_-_NYMEX_-_RBOB.csv', 'group_name': 'Managed Money', 'item_type': 'Net', 'group_column': 'group_name', 'type_column': 'Type', 'title': 'NYMEX - RBOB'},\n",
        "    {'file_path': r'J:\\Strategy and Analytics Group\\Balances\\COT\\CFTC_-_NYMEX_-_NO2.csv', 'group_name': 'Managed Money', 'item_type': 'Net', 'group_column': 'group_name', 'type_column': 'Type', 'title': 'NYMEX - No.2'},\n",
        "    {'file_path': r'J:\\Strategy and Analytics Group\\Balances\\COT\\CFTC_-_NYMEX!ICE_-_COMBINED.csv', 'group_name': 'Managed Money', 'item_type': 'Net', 'group_column': 'group_name', 'type_column': 'Type', 'title': 'NYMEX/ICE - WTI,Brent,RFG,RBOB,No.2,Gasoil'},\n",
        "    {'file_path': r'J:\\Strategy and Analytics Group\\Balances\\COT\\CFTC_-_NYMEX!ICE_-_WTI_BRENT.csv', 'group_name': 'Managed Money', 'item_type': 'Net', 'group_column': 'group_name', 'type_column': 'Type', 'title': 'NYMEX/ICE - WTI,Brent'},\n",
        "    {'file_path': r'J:\\Strategy and Analytics Group\\Balances\\COT\\CFTC_-_NYMEX!ICE_-_NO2_GASOIL.csv', 'group_name': 'Managed Money', 'item_type': 'Net', 'group_column': 'group_name', 'type_column': 'Type', 'title': 'NYMEX/ICE - NO2,Gasoil'},\n",
        "    {'file_path': r'J:\\Strategy and Analytics Group\\Balances\\COT\\CFTC_-_NYMEX_-_ALL.csv', 'group_name': 'Managed Money', 'item_type': 'Net', 'group_column': 'group_name', 'type_column': 'Type', 'title': 'NYMEX - WTI,RFG,RBOB,No.2'},\n",
        "    {'file_path': r'J:\\Strategy and Analytics Group\\Balances\\COT\\CFTC_-_Ags_-_Corn.csv', 'group_name': 'Managed Money', 'item_type': 'Net', 'group_column': 'Group', 'type_column': 'Value Type', 'title': 'Ags - Corn'}\n",
        "]\n",
        "\n",
        "#I went with COT Report but always open to better files name.\n",
        "output_html_path = r'J:\\Strategy and Analytics Group\\Balances\\COT\\COT_Report2.html'\n",
        "\n",
        "analyze_data(files_info, output_html_path)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nfM6mXNgbgcY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}